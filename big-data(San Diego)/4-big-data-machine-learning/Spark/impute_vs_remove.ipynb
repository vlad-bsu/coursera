{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number',\n",
       " 'air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlContext.read.load('file:///home/vlad/Documents/github/my_github_repository/coursera/big-data/4-big-data-machine-learning/notebooks/daily_weather.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true',inferSchema='true')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1095 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1090 not missing values for air_temp_9am:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1090|\n",
      "|   mean| 64.93300141287072|\n",
      "| stddev|11.175514003175877|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('air_temp_9am').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting missing values from whole dataset : 1064 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1064|\n",
      "|   mean| 65.02260949558733|\n",
      "| stddev|11.168033449415704|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removeAllDF = df.na.drop()\n",
    "removeAllDF.describe('air_temp_9am').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean and standard deviation is close to the original values: mean is 64.933 vs. 65.022, and standard deviation is 11.175 vs. 11.168."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impute missing values.** Instead of removing rows containing missing values, let's replace the values with the mean value for that column. First, we'll load the avg function and make a copy of the original DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputeDF = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll iterate through each column in the DataFrame: \n",
    "* compute the mean value for that column \n",
    "* replace any missing values in that column with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number', 545.0018796992481)\n",
      "('air_pressure_9am', 918.9031798641051)\n",
      "('air_temp_9am', 65.02260949558733)\n",
      "('avg_wind_direction_9am', 142.30675564934037)\n",
      "('avg_wind_speed_9am', 5.48579305071369)\n",
      "('max_wind_direction_9am', 148.48042413321315)\n",
      "('max_wind_speed_9am', 6.999713658875691)\n",
      "('rain_accumulation_9am', 0.18202347650615522)\n",
      "('rain_duration_9am', 266.3936973996037)\n",
      "('relative_humidity_9am', 34.07743985327709)\n",
      "('relative_humidity_3pm', 35.14838093290533)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "for x in imputeDF.columns:\n",
    "    meanValue = removeAllDF.agg(avg(x)).first()[0]\n",
    "    print(x, meanValue)\n",
    "    imputeDF = imputeDF.na.fill(meanValue, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The agg() function performs an aggregate calculation on the DataFrame and avg(x) specifies to compute the mean on column x. The agg() function returns a DataFrame, first() returns the first Row, and [0] gets the first value.\n",
    "\n",
    "* The last line of code uses na.fill() to replace the missing values with the mean value (first argument) in column x (second argument).\n",
    "\n",
    "* The output of executing this cell prints the mean values for each column and we can see the mean value for air_temp_9am is the same as the mean when we removed all the missing values in step 4, i.e., 65.022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1095|\n",
      "|   mean| 64.93341058219825|\n",
      "| stddev|11.149948199920228|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputeDF.describe('air_temp_9am').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1090|\n",
      "|   mean| 64.93300141287072|\n",
      "| stddev|11.175514003175877|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('air_temp_9am').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. If we remove all missing values from the data, how many air pressure at 9am measurements have values between 911.736 and 914.67?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeAllDF.filter(df.air_pressure_9am > 911.736).filter(df.air_pressure_9am < 914.67).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. If we impute the missing values with the minimum value, how many air temperature at 9am measurements are less than 42.292?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min as spark_min\n",
    "imputeMin = df\n",
    "for x in imputeMin.columns:\n",
    "    meanValue = removeAllDF.agg(spark_min(x)).first()[0]\n",
    "    imputeMin = imputeMin.na.fill(meanValue, [x])\n",
    "    \n",
    "print imputeMin.filter(imputeMin.air_temp_9am < 42.292).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many samples have missing values for air_pressure_9am?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() - df.na.drop(subset=['air_pressure_9am']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Which column in the weather dataset has the most number of missing values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary                   count\n",
      "number                     1095\n",
      "air_pressure_9am           1092\n",
      "air_temp_9am               1090\n",
      "avg_wind_direction_9am     1091\n",
      "avg_wind_speed_9am         1092\n",
      "max_wind_direction_9am     1092\n",
      "max_wind_speed_9am         1091\n",
      "rain_accumulation_9am      1089\n",
      "rain_duration_9am          1092\n",
      "relative_humidity_9am      1095\n",
      "relative_humidity_3pm      1095\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Minimum value : 1089\n"
     ]
    }
   ],
   "source": [
    "print df.describe().toPandas().transpose()[0]\n",
    "print '\\nMinimum value :', min(df.describe().toPandas().transpose()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. When we remove all the missing values from the dataset, the number of rows is 1064, yet the variable with most missing values has 1089 rows. Why did the number of rows decrease so much?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing values in each column are not necessarily in the same row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
