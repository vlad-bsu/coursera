{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "name": "",
  "signature": "sha256:6682a3aaa6190925f21a748ef9a96c1d179189938a12b047ec03176a05171909"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Import and create a new SQLContext \n",
      "from pyspark.sql import SQLContext\n",
      "from pyspark import SparkContext\n",
      "sc = SparkContext()\n",
      "sqlContext = SQLContext(sc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the country CSV file into an RDD.\n",
      "country_lines = sc.textFile('file:///home/vlad/Documents/my_github_repository/coursera/big-data/3-big-data-integration-processing/week 6/country-list.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert each line into a pair of words\n",
      "country_pairs = country_lines.map(lambda line: line.split(\",\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert each pair of words into a tuple\n",
      "country_tuples = country_pairs.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the DataFrame, look at schema and contents\n",
      "countryDF = sqlContext.createDataFrame(country_tuples, [\"country\", \"code\"])\n",
      "countryDF.printSchema()\n",
      "countryDF.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "root\n",
        " |-- country: string (nullable = true)\n",
        " |-- code: string (nullable = true)\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[Row(country=u'Afghanistan', code=u' AFG'),\n",
        " Row(country=u'Albania', code=u' ALB'),\n",
        " Row(country=u'Algeria', code=u' ALG')]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read tweets CSV file into RDD of lines\n",
      "locations_lines = sc.textFile('file:///home/vlad/Documents/my_github_repository/coursera/big-data/3-big-data-integration-processing/week 6/locations.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean the data: some tweets are empty. Remove the empty tweets using filter() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the DataFrame of tweet word counts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Join the country and tweet data frames (on the appropriate column)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 1: number of distinct countries mentioned\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 2: number of countries mentioned in tweets.\n",
      "from pyspark.sql.functions import sum\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Table 1: top three countries and their counts.\n",
      "from pyspark.sql.functions import desc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Table 2: counts for Wales, Iceland, and Japan.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}