<meta charset="utf-8"/>
<h3>
 Question 1
</h3>
<co-content>
 <p>
  Which hyperparameters are first to tune in sklearn's RandomForest?
 </p>
</co-content>
<form>
 <label>
  <input name="0" type="radio"/>
  <co-content>
   <span>
    n_estimators, max_depth, min_samples_split.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="radio"/>
  <co-content>
   <span>
    n_jobs, random_state, verbose.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="radio"/>
  <co-content>
   <span>
    bootstrap, oob_score, warm_start.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 2
</h3>
<co-content>
 <p>
  Suppose you fit LightGBM to your train data and check performance on the validation set.  The train set consists of 500 rows and 1000 different features and validation set consist of 50 objects.  You run automatic hyperparameter optimization method overnight and in the morning you select the best parameters, produce results for the test set and submit to the leaderboard. We also know that test set comes from the same distribution as train and validation sets.
 </p>
</co-content>
<form>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    There is a low chance of overfitting to the validation set. That is, there is a high chance that score on the test set will be good.  This is because we found good parameters on validation set and test set is similar to the test set.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    There is a high chance of overfitting to the validation set. That is, there is a high chance that score on the test set will be bad.  This is because we've tried too much hyperparameters while the dataset is small and the number of features is large.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 3
</h3>
<co-content>
 <p>
  Suppose you want to find a good set of hyperparameters for a dataset with 1000 points  and have resources to do fitting 2000 times. Which method of model selection your should use?
 </p>
</co-content>
<form>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    k-Fold scheme (i.e. split data into k part, use k-1 parts for training and the last one for quality estimation; repeat for each part)
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    Select model by quality on training set (i.e. fit model on whole dataset and measure quality on the same data).
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    Leave-one-out validation (i.e. fit model for all points except one and estimate quality for this single point; repeat for every point).
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    Hold-Out scheme (i.e. divide data into two parts, use first for model fitting and second for estimation of quality).
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 4
</h3>
<co-content>
 <p>
  Suppose you train Neural Network with SGD and see that it overfits data. Which of the following actions can help you to regularize model?
 </p>
</co-content>
<form>
 <label>
  <input name="3" type="checkbox"/>
  <co-content>
   <span>
    Add (or increase) Weight Decay.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="checkbox"/>
  <co-content>
   <span>
    Reduce number of parameters (e.g. remove some layers)
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="checkbox"/>
  <co-content>
   <span>
    Insert (or increase rate of) Dropout layers inside NN.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="checkbox"/>
  <co-content>
   <span>
    Add more layers.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="checkbox"/>
  <co-content>
   <span>
    Change optimization method to Adam.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
