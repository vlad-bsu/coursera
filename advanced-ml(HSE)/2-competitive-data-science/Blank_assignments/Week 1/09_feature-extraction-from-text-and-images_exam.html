<meta charset="utf-8"/>
<h3>
 Question 1
</h3>
<co-content>
 <p>
  Select true statements about n-grams
 </p>
</co-content>
<form>
 <label>
  <input name="0" type="checkbox"/>
  <co-content>
   <span>
    N-grams can help utilize local context around each word
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="checkbox"/>
  <co-content>
   <span>
    N-grams features are typically sparse
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="checkbox"/>
  <co-content>
   <span>
    Levenshteining should always be applied before computing n-grams
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="checkbox"/>
  <co-content>
   <span>
    N-grams always help increase significance of important words
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 2
</h3>
<co-content>
 <p>
  Select true statements.
 </p>
</co-content>
<form>
 <label>
  <input name="1" type="checkbox"/>
  <co-content>
   <span>
    Bag of words usually produces longer vectors than Word2vec
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="checkbox"/>
  <co-content>
   <span>
    Meaning of each value in BOW matrix is unknown.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="checkbox"/>
  <co-content>
   <span>
    Semantically similar words usually have similar word2vec embeddings.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="checkbox"/>
  <co-content>
   <span>
    You do not need bag of words features in a competition if you have word2vec features.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 3
</h3>
<co-content>
 <p>
  Suppose in a new competition we are given a dataset of 2D medical images. We want to extract image descriptors from a hidden layer of a neural network pretrained on the ImageNet dataset. We will then use extracted descriptors to train a simple logistic regression model to classify images from our dataset.
 </p>
 <p>
  We consider to use two networks: ResNet-50 with imagenet accuracy of X and VGG-16 with imageNet accuracy of Y (X &lt; Y). Select true statements.
 </p>
</co-content>
<form>
 <label>
  <input name="2" type="checkbox"/>
  <co-content>
   <span>
    Descriptors from ResNet-50 and from VGG-16 are always very similar in cosine distance.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="checkbox"/>
  <co-content>
   <span>
    With one pretrained CNN model you can get only one vector of descriptors for an image
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="checkbox"/>
  <co-content>
   <span>
    It is not clear what descriptors are better on our dataset. We should evaluate both.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="checkbox"/>
  <co-content>
   <span>
    Descriptors from ResNet 50 will always be better than the ones from VGG-16 in our pipeline.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="checkbox"/>
  <co-content>
   <span>
    For any image descriptors from the last hidden layer of ResNet-50 are the same as the descriptors from the last hidden layer of VGG-16.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 4
</h3>
<co-content>
 <p>
  Data augmentation can be used at (1) train time (2) test time
 </p>
</co-content>
<form>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    False, True
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    False, False
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    True, False
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    True, True
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
